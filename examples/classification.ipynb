{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553bedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Using cpu device\n",
      "CUDA version: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from classificationutils.resnet import ResNet50\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"\\n Using {device} device\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b392b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/SVHN\\train_32x32.mat\n",
      "Using downloaded and verified file: data/SVHN\\test_32x32.mat\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4376821, 0.4437697, 0.47280442), (0.19803012, 0.20101562, 0.19703614)),\n",
    "])\n",
    "\n",
    "training_data = datasets.SVHN(\n",
    "    root=\"data/SVHN\",\n",
    "    split='train',\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "test_data = datasets.SVHN(\n",
    "    root=\"data/SVHN\",\n",
    "    split='test',\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "transform_test_cifar = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "ood_test_data = datasets.CIFAR10(\n",
    "    root=\"data/CIFAR10\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test_cifar\n",
    ") \n",
    "\n",
    "n_output = 10\n",
    "n_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b28939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s4531973\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNet50(in_channels=n_channels, num_classes = n_output)\n",
    "net.load_state_dict(torch.load('data/resnet50_trained_svhn.pt', weights_only=True, map_location=torch.device(device)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f54603d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "classificationParallel.train() got an unexpected keyword argument 'extra_verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnuqls\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mposterior\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Nuqls\n\u001b[0;32m      3\u001b[0m nuqls_posterior \u001b[38;5;241m=\u001b[39m Nuqls(net, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m loss,acc \u001b[38;5;241m=\u001b[39m \u001b[43mnuqls_posterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtrain_bs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m152\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mn_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0025\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mextra_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m id_logits \u001b[38;5;241m=\u001b[39m nuqls_posterior\u001b[38;5;241m.\u001b[39mtest(test_data, test_bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m152\u001b[39m) \n\u001b[0;32m     16\u001b[0m id_predictions \u001b[38;5;241m=\u001b[39m id_logits\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: classificationParallel.train() got an unexpected keyword argument 'extra_verbose'"
     ]
    }
   ],
   "source": [
    "from nuqls.posterior import Nuqls\n",
    "\n",
    "nuqls_posterior = Nuqls(net, task='classification')\n",
    "loss,acc = nuqls_posterior.train(train=training_data, \n",
    "                    train_bs=152, \n",
    "                    n_output=n_output,\n",
    "                    S=10,\n",
    "                    scale=0.0025, \n",
    "                    lr=1e-2, \n",
    "                    epochs=2, \n",
    "                    mu=0.9,\n",
    "                    verbose=True,\n",
    "                    extra_verbose=True)\n",
    "\n",
    "id_logits = nuqls_posterior.test(test_data, test_bs=152) \n",
    "id_predictions = id_logits.softmax(dim=2)\n",
    "id_variance = id_predictions.var(0)\n",
    "\n",
    "ood_logits = nuqls_posterior.test(ood_test_data, test_bs=152)\n",
    "ood_predictions = ood_logits.softmax(dim=2)\n",
    "ood_variance = ood_predictions.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuqls_variance = classificationutils.metrics.sort_probabilies(id_predictions.to('cpu'), ood_predictions.to('cpu'), test_data=test_data)\n",
    "nuqls_variance = classificationutils.metrics.add_baseline(nuqls_variance,test_data,ood_test_data)\n",
    "\n",
    "classificationutils.metrics.plot_vmsp(prob_dict=nuqls_variance,\n",
    "                          title=f'SVHN ResNet50',\n",
    "                          save_fig=f\"examples/images/vmsp_plot.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
